{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Template\n",
    "\n",
    "This template provides a structured approach to data analysis using the Data Analysis and Prediction Platform.\n",
    "\n",
    "## Overview\n",
    "- **Purpose**: Perform exploratory data analysis and linear regression modeling\n",
    "- **Platform**: DAPP (Data Analysis and Prediction Platform)\n",
    "- **Target**: Educational data science workflows\n",
    "\n",
    "## Workflow Steps\n",
    "1. Data Loading & Validation\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Data Preprocessing\n",
    "4. Linear Regression Modeling\n",
    "5. Model Evaluation\n",
    "6. Results Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# API Configuration (adjust host/port as needed)\n",
    "API_BASE_URL = \"http://localhost:8000\"\n",
    "API_HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")\n",
    "print(f\"📡 API Base URL: {API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Validation\n",
    "\n",
    "Load your dataset using the platform's secure file upload API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load data from uploaded file via API\n",
    "def load_data_from_api(file_id: str):\n",
    "    \"\"\"Load processed data from the platform API.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/data/{file_id}\")\n",
    "        if response.status_code == 200:\n",
    "            data_info = response.json()\n",
    "            # Load the actual data\n",
    "            df = pd.read_csv(data_info['file_path'])\n",
    "            return df, data_info\n",
    "        else:\n",
    "            print(f\"❌ Error loading data: {response.status_code}\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception loading data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Option 2: Load sample data directly\n",
    "def load_sample_data():\n",
    "    \"\"\"Load sample dataset for demonstration.\"\"\"\n",
    "    # Create sample data if no file is uploaded\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    data = {\n",
    "        'feature_1': np.random.normal(50, 15, n_samples),\n",
    "        'feature_2': np.random.normal(30, 10, n_samples),\n",
    "        'feature_3': np.random.uniform(0, 100, n_samples)\n",
    "    }\n",
    "    \n",
    "    # Create target variable with some correlation\n",
    "    data['target'] = (0.5 * data['feature_1'] + \n",
    "                     0.3 * data['feature_2'] + \n",
    "                     0.2 * data['feature_3'] + \n",
    "                     np.random.normal(0, 5, n_samples))\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load your data here\n",
    "# METHOD 1: Use file_id from uploaded file\n",
    "# file_id = \"your-file-id-here\"  # Replace with actual file ID\n",
    "# df, data_info = load_data_from_api(file_id)\n",
    "\n",
    "# METHOD 2: Use sample data for demonstration\n",
    "df = load_sample_data()\n",
    "print(f\"✅ Data loaded successfully: {df.shape} rows and columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"📊 Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"📈 Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"🔗 Correlation Matrix:\")\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "n_cols = 2\n",
    "n_rows = (len(numeric_columns) + 1) // 2\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    if i < len(axes):\n",
    "        sns.histplot(df[col], bins=20, ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(numeric_columns), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"🧹 Data Cleaning:\")\n",
    "print(f\"Missing values before cleaning: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Option 1: Drop rows with missing values\n",
    "# df_clean = df.dropna()\n",
    "\n",
    "# Option 2: Fill missing values with mean/median\n",
    "df_clean = df.copy()\n",
    "for col in df_clean.select_dtypes(include=[np.number]).columns:\n",
    "    df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "\n",
    "print(f\"Missing values after cleaning: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "# Adjust these column names based on your dataset\n",
    "target_column = 'target'  # Replace with your target variable name\n",
    "feature_columns = [col for col in df_clean.columns if col != target_column]\n",
    "\n",
    "print(f\"🎯 Target variable: {target_column}\")\n",
    "print(f\"📊 Feature variables: {feature_columns}\")\n",
    "\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean[target_column]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linear Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"📚 Training set: {X_train.shape}\")\n",
    "print(f\"🔬 Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Model trained successfully\")\n",
    "print(f\"📊 Model coefficients: {model.coef_}\")\n",
    "print(f\"📈 Model intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"🔮 Predictions generated\")\n",
    "print(f\"Training predictions shape: {y_train_pred.shape}\")\n",
    "print(f\"Test predictions shape: {y_test_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"📊 Model Performance Metrics:\")\n",
    "print(f\"Training MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Training R²: {train_r2:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "if abs(train_r2 - test_r2) > 0.1:\n",
    "    print(\"⚠️  Potential overfitting detected (R² difference > 0.1)\")\n",
    "else:\n",
    "    print(\"✅ Model shows good generalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training data\n",
    "ax1.scatter(y_train, y_train_pred, alpha=0.6)\n",
    "ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "ax1.set_xlabel('Actual Values')\n",
    "ax1.set_ylabel('Predicted Values')\n",
    "ax1.set_title(f'Training Set: Actual vs Predicted\\nR² = {train_r2:.4f}')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Test data\n",
    "ax2.scatter(y_test, y_test_pred, alpha=0.6, color='orange')\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax2.set_xlabel('Actual Values')\n",
    "ax2.set_ylabel('Predicted Values')\n",
    "ax2.set_title(f'Test Set: Actual vs Predicted\\nR² = {test_r2:.4f}')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (coefficient analysis)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Coefficient': model.coef_,\n",
    "    'Abs_Coefficient': np.abs(model.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='Abs_Coefficient', y='Feature')\n",
    "plt.title('Feature Importance (Absolute Coefficients)')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Feature Importance:\")\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Export\n",
    "\n",
    "Save your analysis results and model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results summary\n",
    "results_summary = {\n",
    "    'model_type': 'Linear Regression',\n",
    "    'dataset_shape': df_clean.shape,\n",
    "    'features': feature_columns,\n",
    "    'target': target_column,\n",
    "    'train_test_split': {'train': X_train.shape[0], 'test': X_test.shape[0]},\n",
    "    'performance_metrics': {\n",
    "        'train_mse': float(train_mse),\n",
    "        'test_mse': float(test_mse),\n",
    "        'train_r2': float(train_r2),\n",
    "        'test_r2': float(test_r2)\n",
    "    },\n",
    "    'model_parameters': {\n",
    "        'coefficients': model.coef_.tolist(),\n",
    "        'intercept': float(model.intercept_)\n",
    "    },\n",
    "    'feature_importance': feature_importance.to_dict('records')\n",
    "}\n",
    "\n",
    "print(\"📄 Results Summary:\")\n",
    "print(json.dumps(results_summary, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_filename = f\"analysis_results_{timestamp}.json\"\n",
    "\n",
    "# Save to exports directory\n",
    "export_path = Path(\"../data/processed/exports\") / results_filename\n",
    "export_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(export_path, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"✅ Results saved to: {export_path}\")\n",
    "\n",
    "# Optional: Save predictions to CSV\n",
    "predictions_df = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'predicted': y_test_pred,\n",
    "    'residual': y_test - y_test_pred\n",
    "})\n",
    "\n",
    "predictions_filename = f\"predictions_{timestamp}.csv\"\n",
    "predictions_path = Path(\"../data/processed/exports\") / predictions_filename\n",
    "predictions_df.to_csv(predictions_path, index=False)\n",
    "\n",
    "print(f\"✅ Predictions saved to: {predictions_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "### Analysis Summary\n",
    "\n",
    "- **Dataset**: Analyzed a dataset with {df_clean.shape[0]} samples and {df_clean.shape[1]} features\n",
    "- **Model**: Linear Regression with R² score of {test_r2:.4f} on test data\n",
    "- **Key Insights**: [Add your domain-specific insights here]\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Model Improvement**: Consider feature engineering or regularization\n",
    "2. **Additional Analysis**: Explore non-linear relationships\n",
    "3. **Validation**: Test on new datasets\n",
    "4. **Deployment**: Use the platform's model service for production\n",
    "\n",
    "### Platform Features Used\n",
    "\n",
    "- ✅ Secure data loading\n",
    "- ✅ Exploratory data analysis\n",
    "- ✅ Linear regression modeling\n",
    "- ✅ Model evaluation\n",
    "- ✅ Results export\n",
    "\n",
    "---\n",
    "\n",
    "*This analysis was completed using the Data Analysis and Prediction Platform (DAPP)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}