{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Performance Analysis Workflow\n",
    "\n",
    "Educational data analysis demonstrating academic performance prediction and factor analysis.\n",
    "\n",
    "## Dataset Overview\n",
    "- **300 student records** across multiple schools and grade levels\n",
    "- **Academic metrics**: Subject scores, GPA, study habits\n",
    "- **Research questions**: What factors predict academic success? How do different variables interact?\n",
    "\n",
    "## Analysis Objectives\n",
    "1. Identify key factors affecting academic performance\n",
    "2. Build predictive model for GPA\n",
    "3. Analyze differences across schools and grades\n",
    "4. Provide actionable insights for educators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"Set2\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üìö Student Performance Analysis Environment Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the student performance dataset\n",
    "try:\n",
    "    df = pd.read_csv('../sample_datasets/student_performance.csv')\n",
    "    print(\"‚úÖ Loaded student performance dataset\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found. Please run the sample data generator first.\")\n",
    "    # Create demo dataset\n",
    "    np.random.seed(42)\n",
    "    n = 50\n",
    "    df = pd.DataFrame({\n",
    "        'student_id': [f'STU_{i:03d}' for i in range(1, n+1)],\n",
    "        'school': np.random.choice(['School_A', 'School_B'], n),\n",
    "        'grade': np.random.choice(['10th', '11th', '12th'], n),\n",
    "        'study_hours_per_week': np.random.uniform(5, 20, n),\n",
    "        'attendance_rate': np.random.uniform(70, 100, n),\n",
    "        'math_score': np.random.uniform(60, 95, n),\n",
    "        'science_score': np.random.uniform(65, 100, n),\n",
    "        'english_score': np.random.uniform(70, 98, n),\n",
    "        'gpa': np.random.uniform(2.0, 4.0, n),\n",
    "        'extracurricular': np.random.choice(['Sports', 'Music', 'None'], n),\n",
    "        'parent_education': np.random.choice(['High School', 'Bachelor', 'Master'], n)\n",
    "    })\n",
    "    print(\"üìù Using demo dataset for illustration\")\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\nüìä Dataset loaded: {df.shape[0]} students, {df.shape[1]} variables\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Educational Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print(\"üìã STUDENT DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total students: {df.shape[0]}\")\n",
    "print(f\"Variables tracked: {df.shape[1]}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# School and grade distribution\n",
    "if 'school' in df.columns:\n",
    "    print(f\"\\nüè´ Schools represented: {df['school'].nunique()}\")\n",
    "    print(df['school'].value_counts())\n",
    "\n",
    "if 'grade' in df.columns:\n",
    "    print(f\"\\nüìö Grade levels:\")\n",
    "    print(df['grade'].value_counts().sort_index())\n",
    "\n",
    "# Academic performance overview\n",
    "academic_cols = ['math_score', 'science_score', 'english_score', 'gpa']\n",
    "academic_cols = [col for col in academic_cols if col in df.columns]\n",
    "\n",
    "if academic_cols:\n",
    "    print(f\"\\nüìä Academic Performance Summary:\")\n",
    "    display(df[academic_cols].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Academic performance distributions\n",
    "if academic_cols:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(academic_cols[:4]):\n",
    "        if i < len(axes):\n",
    "            df[col].hist(bins=15, ax=axes[i], alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(f'Distribution of {col.replace(\"_\", \" \").title()}')\n",
    "            axes[i].set_xlabel(col.replace(\"_\", \" \").title())\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics\n",
    "            mean_val = df[col].mean()\n",
    "            std_val = df[col].std()\n",
    "            axes[i].axvline(mean_val, color='red', linestyle='--', alpha=0.8, label=f'Mean: {mean_val:.1f}')\n",
    "            axes[i].legend()\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    for i in range(len(academic_cols), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Grade level analysis\n",
    "if 'grade' in df.columns and 'gpa' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x='grade', y='gpa')\n",
    "    plt.title('GPA Distribution by Grade Level')\n",
    "    plt.ylabel('GPA')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìà GPA by Grade Level:\")\n",
    "    grade_stats = df.groupby('grade')['gpa'].agg(['mean', 'std', 'count']).round(3)\n",
    "    display(grade_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Study Habits and Behavioral Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study habits analysis\n",
    "behavioral_cols = ['study_hours_per_week', 'attendance_rate']\n",
    "behavioral_cols = [col for col in behavioral_cols if col in df.columns]\n",
    "\n",
    "if behavioral_cols:\n",
    "    fig, axes = plt.subplots(1, len(behavioral_cols), figsize=(6*len(behavioral_cols), 5))\n",
    "    if len(behavioral_cols) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(behavioral_cols):\n",
    "        if i < len(axes):\n",
    "            # Distribution\n",
    "            df[col].hist(bins=15, ax=axes[i], alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(f'Distribution of {col.replace(\"_\", \" \").title()}')\n",
    "            axes[i].set_xlabel(col.replace(\"_\", \" \").title())\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Study hours vs academic performance\n",
    "if 'study_hours_per_week' in df.columns and 'gpa' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['study_hours_per_week'], df['gpa'], alpha=0.6)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df['study_hours_per_week'], df['gpa'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df['study_hours_per_week'], p(df['study_hours_per_week']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Study Hours per Week')\n",
    "    plt.ylabel('GPA')\n",
    "    plt.title('Study Hours vs GPA')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = df['study_hours_per_week'].corr(df['gpa'])\n",
    "    plt.text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=plt.gca().transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üìö Study Hours Impact: Correlation with GPA = {corr:.3f}\")\n",
    "\n",
    "# Attendance vs performance\n",
    "if 'attendance_rate' in df.columns and 'gpa' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['attendance_rate'], df['gpa'], alpha=0.6, color='orange')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df['attendance_rate'], df['gpa'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df['attendance_rate'], p(df['attendance_rate']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Attendance Rate (%)')\n",
    "    plt.ylabel('GPA')\n",
    "    plt.title('Attendance Rate vs GPA')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = df['attendance_rate'].corr(df['gpa'])\n",
    "    plt.text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=plt.gca().transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üéØ Attendance Impact: Correlation with GPA = {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Subject Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject score correlations\n",
    "subject_cols = ['math_score', 'science_score', 'english_score']\n",
    "subject_cols = [col for col in subject_cols if col in df.columns]\n",
    "\n",
    "if len(subject_cols) > 1:\n",
    "    # Correlation matrix for subjects\n",
    "    subject_corr = df[subject_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(subject_corr, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Subject Score Correlations')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Subject performance comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df[subject_cols].boxplot()\n",
    "    plt.title('Subject Score Distributions')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Subject averages\n",
    "    print(\"\\nüìä Subject Performance Summary:\")\n",
    "    subject_means = df[subject_cols].mean().sort_values(ascending=False)\n",
    "    for subject, mean_score in subject_means.items():\n",
    "        print(f\"  {subject.replace('_', ' ').title()}: {mean_score:.1f}\")\n",
    "    \n",
    "    # Identify high/low performers\n",
    "    if 'gpa' in df.columns:\n",
    "        high_performers = df[df['gpa'] >= df['gpa'].quantile(0.8)]\n",
    "        low_performers = df[df['gpa'] <= df['gpa'].quantile(0.2)]\n",
    "        \n",
    "        print(f\"\\nüéì High Performers (top 20%, GPA ‚â• {df['gpa'].quantile(0.8):.2f}): {len(high_performers)} students\")\n",
    "        if len(high_performers) > 0:\n",
    "            print(\"   Average subject scores:\")\n",
    "            for col in subject_cols:\n",
    "                print(f\"     {col.replace('_', ' ').title()}: {high_performers[col].mean():.1f}\")\n",
    "        \n",
    "        print(f\"\\nüìâ Low Performers (bottom 20%, GPA ‚â§ {df['gpa'].quantile(0.2):.2f}): {len(low_performers)} students\")\n",
    "        if len(low_performers) > 0:\n",
    "            print(\"   Average subject scores:\")\n",
    "            for col in subject_cols:\n",
    "                print(f\"     {col.replace('_', ' ').title()}: {low_performers[col].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Socioeconomic and Environmental Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracurricular activities impact\n",
    "if 'extracurricular' in df.columns and 'gpa' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x='extracurricular', y='gpa')\n",
    "    plt.title('GPA by Extracurricular Activity')\n",
    "    plt.ylabel('GPA')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical analysis\n",
    "    print(\"\\nüé® Extracurricular Activities Impact:\")\n",
    "    extracurricular_stats = df.groupby('extracurricular')['gpa'].agg(['mean', 'std', 'count']).round(3)\n",
    "    display(extracurricular_stats)\n",
    "    \n",
    "    # ANOVA test\n",
    "    groups = [group['gpa'].values for name, group in df.groupby('extracurricular')]\n",
    "    if len(groups) > 1:\n",
    "        f_stat, p_value = stats.f_oneway(*groups)\n",
    "        print(f\"\\nANOVA Test Results:\")\n",
    "        print(f\"  F-statistic: {f_stat:.3f}\")\n",
    "        print(f\"  p-value: {p_value:.3f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"  ‚úÖ Significant difference between extracurricular groups\")\n",
    "        else:\n",
    "            print(\"  ‚ùå No significant difference between extracurricular groups\")\n",
    "\n",
    "# Parent education impact\n",
    "if 'parent_education' in df.columns and 'gpa' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x='parent_education', y='gpa')\n",
    "    plt.title('GPA by Parent Education Level')\n",
    "    plt.ylabel('GPA')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüéì Parent Education Impact:\")\n",
    "    parent_ed_stats = df.groupby('parent_education')['gpa'].agg(['mean', 'std', 'count']).round(3)\n",
    "    display(parent_ed_stats.sort_values('mean', ascending=False))\n",
    "\n",
    "# School comparison\n",
    "if 'school' in df.columns and 'gpa' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x='school', y='gpa')\n",
    "    plt.title('GPA by School')\n",
    "    plt.ylabel('GPA')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüè´ School Performance Comparison:\")\n",
    "    school_stats = df.groupby('school')['gpa'].agg(['mean', 'std', 'count']).round(3)\n",
    "    display(school_stats.sort_values('mean', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictive Modeling for Academic Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for GPA prediction\n",
    "if 'gpa' in df.columns:\n",
    "    print(\"üéØ BUILDING GPA PREDICTION MODEL\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Select features (exclude GPA and student ID)\n",
    "    feature_candidates = [col for col in df.columns if col not in ['gpa', 'student_id']]\n",
    "    \n",
    "    # Create encoded dataset\n",
    "    df_encoded = df.copy()\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    for col in feature_candidates:\n",
    "        if df[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            df_encoded[col] = le.fit_transform(df[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Select features and target\n",
    "    X = df_encoded[feature_candidates]\n",
    "    y = df_encoded['gpa']\n",
    "    \n",
    "    print(f\"Features used: {list(X.columns)}\")\n",
    "    print(f\"Target variable: GPA\")\n",
    "    print(f\"Dataset size: {len(X)} students, {len(X.columns)} features\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Training set: {len(X_train)} students\")\n",
    "    print(f\"Test set: {len(X_test)} students\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå GPA column not found. Skipping modeling.\")\n",
    "    X_train = X_test = y_train = y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "if X_train is not None:\n",
    "    # Multiple models for comparison\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    model_results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        # Metrics\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "        test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "        \n",
    "        model_results[name] = {\n",
    "            'model': model,\n",
    "            'train_r2': train_r2,\n",
    "            'test_r2': test_r2,\n",
    "            'test_mse': test_mse,\n",
    "            'test_mae': test_mae,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'predictions': y_pred_test\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(f\"  Train R¬≤: {train_r2:.4f}\")\n",
    "        print(f\"  Test R¬≤: {test_r2:.4f}\")\n",
    "        print(f\"  Test RMSE: {np.sqrt(test_mse):.4f}\")\n",
    "        print(f\"  Test MAE: {test_mae:.4f}\")\n",
    "        print(f\"  CV R¬≤ (mean ¬± std): {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "    \n",
    "    # Select best model\n",
    "    best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['test_r2'])\n",
    "    best_model = model_results[best_model_name]['model']\n",
    "    best_predictions = model_results[best_model_name]['predictions']\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "    print(f\"Test R¬≤: {model_results[best_model_name]['test_r2']:.4f}\")\n",
    "    print(f\"Average GPA prediction error: ¬±{model_results[best_model_name]['test_mae']:.3f} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation and feature importance\n",
    "if X_train is not None and len(model_results) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Predicted vs Actual\n",
    "    axes[0,0].scatter(y_test, best_predictions, alpha=0.6)\n",
    "    axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[0,0].set_xlabel('Actual GPA')\n",
    "    axes[0,0].set_ylabel('Predicted GPA')\n",
    "    axes[0,0].set_title(f'GPA Prediction Accuracy ({best_model_name})')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add R¬≤ annotation\n",
    "    r2 = model_results[best_model_name]['test_r2']\n",
    "    axes[0,0].text(0.05, 0.95, f'R¬≤ = {r2:.3f}', transform=axes[0,0].transAxes,\n",
    "                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Residuals plot\n",
    "    residuals = y_test - best_predictions\n",
    "    axes[0,1].scatter(best_predictions, residuals, alpha=0.6)\n",
    "    axes[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[0,1].set_xlabel('Predicted GPA')\n",
    "    axes[0,1].set_ylabel('Residuals')\n",
    "    axes[0,1].set_title('Prediction Residuals')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Model comparison\n",
    "    model_names = list(model_results.keys())\n",
    "    test_r2_scores = [model_results[name]['test_r2'] for name in model_names]\n",
    "    cv_means = [model_results[name]['cv_mean'] for name in model_names]\n",
    "    \n",
    "    x_pos = np.arange(len(model_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1,0].bar(x_pos - width/2, test_r2_scores, width, label='Test R¬≤', alpha=0.8)\n",
    "    axes[1,0].bar(x_pos + width/2, cv_means, width, label='CV R¬≤ Mean', alpha=0.8)\n",
    "    axes[1,0].set_xlabel('Models')\n",
    "    axes[1,0].set_ylabel('R¬≤ Score')\n",
    "    axes[1,0].set_title('Model Performance Comparison')\n",
    "    axes[1,0].set_xticks(x_pos)\n",
    "    axes[1,0].set_xticklabels(model_names)\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feature importance (for Random Forest)\n",
    "    if best_model_name == 'Random Forest' and hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "        axes[1,1].barh(feature_importance['feature'], feature_importance['importance'])\n",
    "        axes[1,1].set_xlabel('Feature Importance')\n",
    "        axes[1,1].set_title('Factors Predicting GPA (Random Forest)')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Print top factors\n",
    "        print(\"\\nüéØ Top Factors Predicting GPA:\")\n",
    "        top_features = feature_importance.tail(5)\n",
    "        for _, row in top_features.iterrows():\n",
    "            print(f\"  ‚Ä¢ {row['feature'].replace('_', ' ').title()}: {row['importance']:.3f}\")\n",
    "    else:\n",
    "        axes[1,1].text(0.5, 0.5, 'Feature importance\\nonly available for\\nRandom Forest', \n",
    "                      ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "        axes[1,1].set_title('Feature Importance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Educational Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate educational insights\n",
    "print(\"üéì EDUCATIONAL INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Study habits insights\n",
    "if 'study_hours_per_week' in df.columns and 'gpa' in df.columns:\n",
    "    study_corr = df['study_hours_per_week'].corr(df['gpa'])\n",
    "    avg_study_hours = df['study_hours_per_week'].mean()\n",
    "    if study_corr > 0.3:\n",
    "        insights.append(f\"üìö **Study Habits**: Strong positive correlation ({study_corr:.3f}) between study hours and GPA. Average study time: {avg_study_hours:.1f} hours/week\")\n",
    "    elif study_corr > 0.1:\n",
    "        insights.append(f\"üìö **Study Habits**: Moderate correlation ({study_corr:.3f}) between study hours and GPA suggests quality over quantity\")\n",
    "\n",
    "# Attendance insights\n",
    "if 'attendance_rate' in df.columns and 'gpa' in df.columns:\n",
    "    attendance_corr = df['attendance_rate'].corr(df['gpa'])\n",
    "    avg_attendance = df['attendance_rate'].mean()\n",
    "    if attendance_corr > 0.3:\n",
    "        insights.append(f\"üéØ **Attendance Impact**: Strong correlation ({attendance_corr:.3f}) - attendance is critical for academic success. Average: {avg_attendance:.1f}%\")\n",
    "\n",
    "# Subject performance insights\n",
    "subject_cols = ['math_score', 'science_score', 'english_score']\n",
    "subject_cols = [col for col in subject_cols if col in df.columns]\n",
    "if subject_cols:\n",
    "    subject_means = df[subject_cols].mean()\n",
    "    highest_subject = subject_means.idxmax().replace('_score', '').title()\n",
    "    lowest_subject = subject_means.idxmin().replace('_score', '').title()\n",
    "    insights.append(f\"üìä **Subject Strengths**: Students perform best in {highest_subject} ({subject_means.max():.1f}) and need support in {lowest_subject} ({subject_means.min():.1f})\")\n",
    "\n",
    "# Extracurricular insights\n",
    "if 'extracurricular' in df.columns and 'gpa' in df.columns:\n",
    "    extra_gpa = df.groupby('extracurricular')['gpa'].mean().sort_values(ascending=False)\n",
    "    if len(extra_gpa) > 1:\n",
    "        best_activity = extra_gpa.index[0]\n",
    "        best_gpa = extra_gpa.iloc[0]\n",
    "        insights.append(f\"üé® **Extracurricular Benefits**: Students in {best_activity} have highest average GPA ({best_gpa:.2f})\")\n",
    "\n",
    "# Parent education insights\n",
    "if 'parent_education' in df.columns and 'gpa' in df.columns:\n",
    "    parent_ed_gpa = df.groupby('parent_education')['gpa'].mean().sort_values(ascending=False)\n",
    "    if len(parent_ed_gpa) > 1:\n",
    "        highest_ed = parent_ed_gpa.index[0]\n",
    "        lowest_ed = parent_ed_gpa.index[-1]\n",
    "        gpa_gap = parent_ed_gpa.iloc[0] - parent_ed_gpa.iloc[-1]\n",
    "        insights.append(f\"üë®‚Äçüéì **Socioeconomic Factor**: {gpa_gap:.2f} GPA point gap between students with {highest_ed} vs {lowest_ed} educated parents\")\n",
    "\n",
    "# Model insights\n",
    "if X_train is not None and len(model_results) > 0:\n",
    "    best_r2 = model_results[best_model_name]['test_r2']\n",
    "    mae = model_results[best_model_name]['test_mae']\n",
    "    if best_r2 > 0.7:\n",
    "        insights.append(f\"ü§ñ **Predictive Success**: Academic performance is highly predictable (R¬≤ = {best_r2:.3f}) with ¬±{mae:.2f} GPA error\")\n",
    "    elif best_r2 > 0.5:\n",
    "        insights.append(f\"ü§ñ **Moderate Predictability**: Academic factors explain {best_r2*100:.0f}% of GPA variance\")\n",
    "\n",
    "# School comparison insights\n",
    "if 'school' in df.columns and 'gpa' in df.columns:\n",
    "    school_gpa = df.groupby('school')['gpa'].agg(['mean', 'count'])\n",
    "    if len(school_gpa) > 1:\n",
    "        gpa_range = school_gpa['mean'].max() - school_gpa['mean'].min()\n",
    "        if gpa_range > 0.2:\n",
    "            top_school = school_gpa['mean'].idxmax()\n",
    "            insights.append(f\"üè´ **School Performance Gap**: {gpa_range:.2f} GPA point difference between schools - {top_school} leads\")\n",
    "\n",
    "# Display insights\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i}. {insight}\")\n",
    "\n",
    "print(\"\\nüìã ACTIONABLE RECOMMENDATIONS FOR EDUCATORS:\")\n",
    "print(\"1. **Attendance Intervention**: Implement early warning systems for attendance issues\")\n",
    "print(\"2. **Study Skills Training**: Teach effective study techniques rather than just encouraging more hours\")\n",
    "print(\"3. **Extracurricular Promotion**: Encourage participation in activities that correlate with success\")\n",
    "print(\"4. **Targeted Support**: Provide additional resources for students from disadvantaged backgrounds\")\n",
    "print(\"5. **Subject-Specific Help**: Focus remediation efforts on consistently challenging subjects\")\n",
    "print(\"6. **Predictive Analytics**: Use models to identify at-risk students early in the semester\")\n",
    "print(\"7. **Holistic Assessment**: Consider multiple factors beyond test scores for student evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Educational Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive educational analysis report\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Ensure exports directory exists\n",
    "os.makedirs('../data/processed/exports', exist_ok=True)\n",
    "\n",
    "analysis_summary = {\n",
    "    'analysis_type': 'Student Performance Analysis',\n",
    "    'dataset_info': {\n",
    "        'name': 'student_performance.csv',\n",
    "        'total_students': int(df.shape[0]),\n",
    "        'variables_tracked': int(df.shape[1]),\n",
    "        'schools': df['school'].nunique() if 'school' in df.columns else 0,\n",
    "        'grade_levels': df['grade'].nunique() if 'grade' in df.columns else 0\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'key_insights': insights,\n",
    "    'academic_summary': {}\n",
    "}\n",
    "\n",
    "# Add academic performance statistics\n",
    "if 'gpa' in df.columns:\n",
    "    analysis_summary['academic_summary']['gpa_statistics'] = {\n",
    "        'mean': float(df['gpa'].mean()),\n",
    "        'std': float(df['gpa'].std()),\n",
    "        'min': float(df['gpa'].min()),\n",
    "        'max': float(df['gpa'].max())\n",
    "    }\n",
    "\n",
    "# Add subject performance\n",
    "subject_cols = ['math_score', 'science_score', 'english_score']\n",
    "subject_cols = [col for col in subject_cols if col in df.columns]\n",
    "if subject_cols:\n",
    "    analysis_summary['subject_performance'] = {\n",
    "        col: {\n",
    "            'mean': float(df[col].mean()),\n",
    "            'std': float(df[col].std())\n",
    "        } for col in subject_cols\n",
    "    }\n",
    "\n",
    "# Add model performance\n",
    "if X_train is not None and len(model_results) > 0:\n",
    "    analysis_summary['predictive_model'] = {\n",
    "        'best_model': best_model_name,\n",
    "        'accuracy_r2': float(model_results[best_model_name]['test_r2']),\n",
    "        'prediction_error_mae': float(model_results[best_model_name]['test_mae']),\n",
    "        'features_used': list(X.columns)\n",
    "    }\n",
    "\n",
    "# Add demographic analysis\n",
    "if 'extracurricular' in df.columns:\n",
    "    extracurricular_dist = df['extracurricular'].value_counts().to_dict()\n",
    "    analysis_summary['demographics'] = {\n",
    "        'extracurricular_distribution': {str(k): int(v) for k, v in extracurricular_dist.items()}\n",
    "    }\n",
    "\n",
    "if 'parent_education' in df.columns:\n",
    "    parent_ed_dist = df['parent_education'].value_counts().to_dict()\n",
    "    analysis_summary['demographics']['parent_education_distribution'] = {str(k): int(v) for k, v in parent_ed_dist.items()}\n",
    "\n",
    "# Save analysis results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_filename = f\"student_analysis_results_{timestamp}.json\"\n",
    "\n",
    "with open(f'../data/processed/exports/{results_filename}', 'w') as f:\n",
    "    json.dump(analysis_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"‚úÖ Educational analysis saved to: ../data/processed/exports/{results_filename}\")\n",
    "\n",
    "# Save student predictions if available\n",
    "if X_train is not None and len(model_results) > 0:\n",
    "    # Create predictions dataframe with student context\n",
    "    test_indices = y_test.index\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'student_id': df.loc[test_indices, 'student_id'] if 'student_id' in df.columns else test_indices,\n",
    "        'actual_gpa': y_test.values,\n",
    "        'predicted_gpa': best_predictions,\n",
    "        'prediction_error': np.abs(y_test.values - best_predictions),\n",
    "        'accuracy_category': ['High' if abs(err) < 0.2 else 'Medium' if abs(err) < 0.5 else 'Low' \n",
    "                             for err in (y_test.values - best_predictions)]\n",
    "    })\n",
    "    \n",
    "    predictions_filename = f\"student_gpa_predictions_{timestamp}.csv\"\n",
    "    predictions_df.to_csv(f'../data/processed/exports/{predictions_filename}', index=False)\n",
    "    print(f\"‚úÖ GPA predictions saved to: ../data/processed/exports/{predictions_filename}\")\n",
    "\n",
    "# Performance summary for educators\n",
    "print(\"\\nüéì ANALYSIS SUMMARY FOR EDUCATORS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Students analyzed: {df.shape[0]}\")\n",
    "if 'gpa' in df.columns:\n",
    "    print(f\"üìà Average GPA: {df['gpa'].mean():.2f} (¬±{df['gpa'].std():.2f})\")\n",
    "    high_achievers = len(df[df['gpa'] >= 3.5]) if 'gpa' in df.columns else 0\n",
    "    at_risk = len(df[df['gpa'] < 2.0]) if 'gpa' in df.columns else 0\n",
    "    print(f\"üèÜ High achievers (GPA ‚â• 3.5): {high_achievers} students ({high_achievers/len(df)*100:.1f}%)\")\n",
    "    print(f\"‚ö†Ô∏è At-risk students (GPA < 2.0): {at_risk} students ({at_risk/len(df)*100:.1f}%)\")\n",
    "\n",
    "if X_train is not None and len(model_results) > 0:\n",
    "    print(f\"ü§ñ Prediction accuracy: {model_results[best_model_name]['test_r2']*100:.1f}% (R¬≤)\")\n",
    "    print(f\"üìè Average prediction error: ¬±{model_results[best_model_name]['test_mae']:.2f} GPA points\")\n",
    "\n",
    "print(f\"\\nüí° Key insights discovered: {len(insights)}\")\n",
    "print(f\"üìÅ Analysis files exported: 2 files in exports directory\")\n",
    "print(f\"\\nüéØ Ready for educational decision-making and intervention planning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Educational Analysis Completed ‚úÖ\n",
    "\n",
    "This comprehensive analysis of student performance data provides actionable insights for educators and administrators:\n",
    "\n",
    "**üìö Academic Performance Analysis**\n",
    "- GPA and subject score distributions\n",
    "- Correlation between study habits and outcomes\n",
    "- Identification of high-performing and at-risk students\n",
    "\n",
    "**üéØ Factor Analysis**\n",
    "- Impact of study hours and attendance on academic success\n",
    "- Influence of extracurricular activities\n",
    "- Socioeconomic factors (parent education) effects\n",
    "- School performance comparisons\n",
    "\n",
    "**ü§ñ Predictive Modeling**\n",
    "- GPA prediction with measurable accuracy\n",
    "- Feature importance ranking\n",
    "- Early identification of students needing support\n",
    "\n",
    "**üí° Educational Insights**\n",
    "- Evidence-based recommendations for interventions\n",
    "- Data-driven policy suggestions\n",
    "- Resource allocation guidance\n",
    "\n",
    "### Platform Capabilities Demonstrated\n",
    "\n",
    "‚úÖ **Educational Data Analysis**: Specialized metrics for academic datasets  \n",
    "‚úÖ **Statistical Testing**: ANOVA, correlation analysis, significance testing  \n",
    "‚úÖ **Predictive Analytics**: Student outcome prediction and risk assessment  \n",
    "‚úÖ **Visualization Suite**: Academic performance dashboards  \n",
    "‚úÖ **Export Functionality**: Educator-ready reports and predictions  \n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "1. **Early Warning Systems**: Identify at-risk students before failure\n",
    "2. **Resource Planning**: Allocate tutoring and support based on predictions\n",
    "3. **Policy Development**: Evidence-based educational policy decisions\n",
    "4. **Intervention Design**: Targeted programs for specific student populations\n",
    "5. **Performance Monitoring**: Track institutional and individual progress\n",
    "\n",
    "---\n",
    "*Educational Analysis completed using the Data Analysis and Prediction Platform*"
   ]
  }
 ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.0\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}