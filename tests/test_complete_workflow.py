#!/usr/bin/env python3
"""
Complete workflow test - tests file upload, analysis, model training, and prediction
"""

import requests
import json
import pandas as pd
import time
import os
from pathlib import Path

# Configuration
BASE_URL = "http://localhost:8000"
TEST_USER = "workflow_test_user"
TEST_PASSWORD = "testpass123"
TEST_EMAIL = "workflow@test.com"

def log_step(step, message):
    """Log test step with formatting"""
    print(f"\n{'='*60}")
    print(f"STEP {step}: {message}")
    print('='*60)

def create_test_dataset():
    """Create a proper test dataset for machine learning"""
    data = {
        'house_size': [1200, 1500, 1800, 2000, 2200, 2500, 2800, 3000, 3200, 3500,
                      1100, 1400, 1700, 1900, 2100, 2400, 2700, 2900, 3100, 3400],
        'bedrooms': [2, 3, 3, 4, 4, 4, 5, 5, 5, 6,
                    2, 3, 3, 4, 4, 4, 5, 5, 5, 6],
        'bathrooms': [1, 2, 2, 2, 3, 3, 3, 4, 4, 4,
                     1, 2, 2, 2, 3, 3, 3, 4, 4, 4],
        'age': [5, 10, 15, 20, 8, 12, 18, 25, 3, 7,
               6, 11, 16, 21, 9, 13, 19, 26, 4, 8],
        'price': [250000, 300000, 350000, 400000, 450000, 500000, 550000, 600000, 650000, 700000,
                 240000, 290000, 340000, 390000, 440000, 490000, 540000, 590000, 640000, 690000]
    }
    
    df = pd.DataFrame(data)
    test_file = "/tmp/housing_data_test.csv"
    df.to_csv(test_file, index=False)
    print(f"Created test dataset: {test_file}")
    print(f"Dataset shape: {df.shape}")
    print(f"Columns: {list(df.columns)}")
    return test_file

def test_workflow():
    """Test the complete workflow"""
    
    log_step(1, "Create Test Dataset")
    test_file = create_test_dataset()
    
    log_step(2, "User Registration")
    
    # Register user
    register_data = {
        "username": TEST_USER,
        "email": TEST_EMAIL,
        "password": TEST_PASSWORD
    }
    
    response = requests.post(f"{BASE_URL}/auth/register", json=register_data)
    if response.status_code == 200:
        auth_data = response.json()
        token = auth_data["access_token"]
        print(f"‚úÖ Registration successful. Token: {token[:20]}...")
    else:
        print(f"Registration failed, trying login... {response.text}")
        # Try login instead
        login_data = {"username": TEST_USER, "password": TEST_PASSWORD}
        response = requests.post(f"{BASE_URL}/auth/login", json=login_data)
        if response.status_code == 200:
            auth_data = response.json()
            token = auth_data["access_token"]
            print(f"‚úÖ Login successful. Token: {token[:20]}...")
        else:
            print(f"‚ùå Both registration and login failed: {response.text}")
            return False
    
    headers = {"Authorization": f"Bearer {token}"}
    
    log_step(3, "File Upload")
    
    # Upload file
    with open(test_file, 'rb') as f:
        files = {'file': ('housing_data_test.csv', f, 'text/csv')}
        response = requests.post(f"{BASE_URL}/data/upload", files=files, headers=headers)
    
    if response.status_code == 200:
        upload_result = response.json()
        dataset_id = upload_result.get("dataset_id")
        print(f"‚úÖ File upload successful. Dataset ID: {dataset_id}")
        print(f"Dataset info: {json.dumps(upload_result, indent=2)}")
    else:
        print(f"‚ùå File upload failed: {response.status_code} - {response.text}")
        return False
    
    log_step(4, "Dataset Analysis")
    
    # Analyze dataset
    analysis_request = {
        "include_correlation": True,
        "detect_outliers": True
    }
    
    response = requests.post(
        f"{BASE_URL}/data/datasets/{dataset_id}/analyze",
        json=analysis_request,
        headers=headers
    )
    
    if response.status_code == 200:
        analysis_result = response.json()
        print(f"‚úÖ Dataset analysis successful")
        print(f"Shape: {analysis_result.get('shape')}")
        print(f"Columns: {analysis_result.get('columns')}")
        print(f"Numeric columns: {len(analysis_result.get('numeric_summary', {}))}")
    else:
        print(f"‚ùå Dataset analysis failed: {response.status_code} - {response.text}")
        return False
    
    log_step(5, "Model Training")
    
    # Train model
    training_request = {
        "dataset_id": dataset_id,
        "target_column": "price",
        "feature_columns": ["house_size", "bedrooms", "bathrooms", "age"],
        "model_type": "linear_regression",
        "test_size": 0.2
    }
    
    response = requests.post(f"{BASE_URL}/models/train", json=training_request, headers=headers)
    
    if response.status_code == 200:
        model_result = response.json()
        model_id = model_result.get("model_id")
        print(f"‚úÖ Model training successful. Model ID: {model_id}")
        print(f"Model metrics: {model_result.get('metrics', {})}")
    else:
        print(f"‚ùå Model training failed: {response.status_code} - {response.text}")
        # This might fail if model service isn't fully implemented, continue anyway
        model_id = None
    
    if model_id:
        log_step(6, "Model Prediction")
        
        # Make prediction
        prediction_request = {
            "features": {
                "house_size": 2000,
                "bedrooms": 3,
                "bathrooms": 2,
                "age": 10
            }
        }
        
        response = requests.post(
            f"{BASE_URL}/models/{model_id}/predict",
            json=prediction_request,
            headers=headers
        )
        
        if response.status_code == 200:
            prediction_result = response.json()
            print(f"‚úÖ Prediction successful")
            print(f"Prediction: {prediction_result}")
        else:
            print(f"‚ùå Prediction failed: {response.status_code} - {response.text}")
    
    log_step(7, "List Datasets")
    
    # List datasets
    response = requests.get(f"{BASE_URL}/data/datasets", headers=headers)
    
    if response.status_code == 200:
        datasets_result = response.json()
        datasets = datasets_result.get("datasets", [])
        print(f"‚úÖ Dataset listing successful. Found {len(datasets)} datasets")
        for dataset in datasets:
            print(f"  - {dataset.get('name', 'Unknown')} (ID: {dataset.get('dataset_id', 'Unknown')})")
    else:
        print(f"‚ùå Dataset listing failed: {response.status_code} - {response.text}")
    
    log_step(8, "Cleanup")
    
    # Cleanup test file
    try:
        os.unlink(test_file)
        print(f"‚úÖ Cleaned up test file: {test_file}")
    except:
        print(f"‚ö†Ô∏è  Could not clean up test file: {test_file}")
    
    print(f"\n{'='*60}")
    print("WORKFLOW TEST COMPLETED")
    print('='*60)
    
    return True

if __name__ == "__main__":
    print("üß™ Starting Complete Workflow Test")
    print("This will test: registration ‚Üí upload ‚Üí analysis ‚Üí training ‚Üí prediction")
    
    try:
        success = test_workflow()
        if success:
            print("\nüéâ Workflow test completed successfully!")
        else:
            print("\n‚ùå Workflow test failed!")
    except Exception as e:
        print(f"\nüí• Workflow test crashed: {e}")
        import traceback
        traceback.print_exc()